<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Dr. Xie's Personal Homepage</title><meta name="author"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Dr. Xie's Personal Homepage</a></div></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/photo3.jpg" onerror="this.onerror=null;this.src='/img/favicon.png'" alt="avatar"></div><div class="author-discrip"><h3>谢佳龙(Jialong Xie)</h3><p class="author-bio">山东大学博士研究生，是一位喜欢骑行、徒步、记录生活的人生体验家.  A Ph.D. candidate at Shandong University, I am a life enthusiast who enjoys cycling, hiking, and documenting the little moments of my life.</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://github.com/xiejialong" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto:jolen_xie@qq.com" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://space.bilibili.com/286191903" target="_blank"><i class="fab fa-youtube" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://blog.csdn.net/Jolen_xie" target="_blank"><i class="fa fa-pencil-square" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="https://orcid.org/0009-0000-0232-0049" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">first</h2><article><h1 id="个人简介-Short-Bio"><a href="#个人简介-Short-Bio" class="headerlink" title="个人简介 Short Bio"></a>个人简介 Short Bio</h1><p>目前正在山东大学控制科学与工程学院攻读博士学位, 研究方向语言引导的机器人目标分割与抓取姿态估计.<br>I am studying for a PhD in the School of Control Science and Engineering of Shandong University, researching language-conditioned robot object image segmentation and grasp pose estimation.</p>
<p>在生活中，我尝试做一名冒险家，目前对徒步、露营、土坡车、健身、养宠物感兴趣，喜欢通过相机记录自己生活的点点滴滴，希望抓住最后这一点快乐的读书时光和为数不多的青春，多尝试不一样的东西。<br>In life, I am an adventurer, currently trying hiking, camping, dirty jumping in mountain biking, fitness, pet and other activities. I like to capture the little moments of my life through my camera, hoping to seize these last joyful moments of my student days and the fleeting youth to try as many different things as possible.</p>
<h1 id="感兴趣领域-Interests"><a href="#感兴趣领域-Interests" class="headerlink" title="感兴趣领域 Interests"></a>感兴趣领域 Interests</h1><ul>
<li><p>服务机器人<br>Service Robots</p>
</li>
<li><p>大模型<br>Large Language Model</p>
</li>
<li><p>多模态<br>Multimodaity</p>
</li>
<li><p>人机交互<br>Human-Robot Interaction</p>
</li>
<li><p>具身操作<br>Embodied Manipulation</p>
</li>
<li><p>计算机视觉<br>Computer Vision</p>
</li>
</ul>
<h1 id="教育经历-Education"><a href="#教育经历-Education" class="headerlink" title="教育经历 Education"></a>教育经历 Education</h1><ul>
<li>2015年9月-2019年6月：杭州电子科技大学自动化学院获得学士学位<br>September 2015 - June 2019: B.S. Degree from School of Automation, Hangzhou Dianzi University</li>
<li>2022年7月-2022年9月：俄罗斯ITMO大学控制系统与机器人国际夏令营<br>July 2022 - September 2022: International Summer School for Control Systems and Robotics, ITMO University, Russia</li>
<li>2019年9月-2022年6月：杭州电子科技大学自动化学院获得硕士学位<br>September 2019 - June 2022: M.S. degree from School of Automation, Hangzhou Dianzi University</li>
</ul>
<h1 id="学术论文-Publications"><a href="#学术论文-Publications" class="headerlink" title="学术论文 Publications"></a>学术论文 Publications</h1><ul>
<li><p><strong>Xie J,</strong> Zhang B, Lu Q, et al. A Dynamic Head Gesture Recognition Method for Real-time Intention Inference and Its Application to Visual Human-robot Interaction[J]. <em>International Journal of Control, Automation and Systems</em>, 2024, 22(1): 252-264.</p>
</li>
<li><p><strong>J. Xie</strong>, J. Liu, S. Huang, C. Wang and F. Zhou, “Listen, Perceive, Grasp: CLIP-Driven Attribute-Aware Network for Language-Conditioned Visual Segmentation and Grasping,” in <em>IEEE Transactions on Automation Science and Engineering</em>, doi: 10.1109&#x2F;TASE.2024.3510777.</p>
</li>
<li><p><strong>J. Xie</strong>, J. Liu, Z. Zhu, C. Wang, P. Duan and F. Zhou, “Infusing Multisource Heterogeneous Knowledge for Language-Conditioned Segmentation and Grasping,” in <em>IEEE Transactions on Instrumentation and Measurement</em>, vol. 73, pp. 1-11, 2024.</p>
</li>
<li><p><strong>Xie J</strong>, Liu J, Wang G, et al. SATR: Semantics-Aware Triadic Refinement network for referring image segmentation[J]. <em>Knowledge-Based Systems</em>, 2024, 284: 111243.</p>
</li>
<li><p><strong>J. Xie</strong>, F. Zhou, J. Liu and C. Wang, “Semi-Supervised Language-Conditioned Grasping With Curriculum-Scheduled Augmentation and Geometric Consistency,” in <em>IEEE Robotics and Automation Letters</em>, vol. 10, no. 4, pp. 4021-4028.</p>
</li>
<li><p><strong>谢佳龙</strong>,张波涛,吕强.一种基于双流融合3D卷积神经网络的动态头势识别方法[J].电子学报,2021,49(07):1363-1369.</p>
</li>
<li><p>J. Liu, <strong>J. Xie</strong>, L. Xiao, C. Wang and F. Zhou, “Hierarchical Multi-Modal Fusion for Language-Conditioned Robotic Grasping Detection in Clutter,” in <em>IEEE Robotics and Automation Letters</em>, vol. 9, no. 10, pp. 8762-8769.</p>
</li>
<li><p>J. Liu, <strong>J. Xie</strong>, S. Huang, C. Wang and F. Zhou, “Continual Learning for Robotic Grasping Detection With Knowledge Transferring,” in <em>IEEE Transactions on Industrial Electronics</em>, vol. 71, no. 9, pp. 11019-11027..</p>
</li>
<li><p>J. Liu, <strong>J. Xie</strong>, F. Zhou and S. He, “Question Type-Aware Debiasing for Test-Time Visual Question Answering Model Adaptation,” in <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, vol. 34, no. 11, pp. 10805-10816, Nov. 2024.</p>
</li>
<li><p>Liu J, <strong>Xie J L</strong>, Zhou F, et al. Triadic temporal-semantic alignment for weakly-supervised video moment retrieval[J]. Pattern Recognition, 2024, 156: 110819.</p>
</li>
</ul>
<h1 id="项目经历-Project-Experience"><a href="#项目经历-Project-Experience" class="headerlink" title="项目经历 Project Experience"></a>项目经历 Project Experience</h1><ul>
<li><p><strong>国家重点研发计划项目+山东省重点研发计划项目</strong>：机场作业机器人云-边-端具身智能关键技术研究, 2023.9 - 至今.</p>
<p>负责<strong>视觉-语言图像目标分割与机器人抓取姿态估计</strong>，主要完成项目多模态感知：</p>
<p>（1）设计指代目标图像分割模型，使用Swin Transformer做视觉编码器、RoBERTa做语言编码器，设计语言引导的像素解析模块，在Swin Transformer中实现语言特征融入，结合边界、细节与显著特征实现三元特征融合，构建多任务训练损失；</p>
<p>（2）微调CLIP模型作为视觉与文本编码器，实现复杂场景下隐式文本-图像对齐特征提取，通过GPT-4生成实体常识知识并设计异构多源知识融合策略，构建高精细度解码器结构，实现混乱场景下的多模态感知。</p>
<p>（3）为提高少量语言-视觉数据训练的有效性，构建基于课程学习计划的数据增强方案，设计学生-教师知识蒸馏网络，并构建视觉几何一致性正则策略。相关工作整理论文4篇。</p>
<div style="text-align: center;">
    <img src="https://research.xiejialong.top/seg.jpg" />
</div>

</li>
<li><p><strong>美团机器人研究院科研合作项目：</strong>基于具身智能的混乱场景自适应持续抓取方法研究, 2024.3 - 2025.3.</p>
<p>主要负责<strong>基于大模型的机器人行为控制与决策代码生成</strong>，主要完成构建大模型-机器人结合的Agent框架，使用GPT-4作为大模型基础构建Prompt工程，将机器人感知信息（目标位置、语音指令等）作为动态输入Prompt、定义机器人API手册作为Tool-Use Prompt并迭代选择Top-K个优秀历史行为数据作为CoT与Memory Prompt，使用GPT-4补充感知目标的常识知识信息并构建场景知识图谱，实现机器人在目标遮挡下的细粒度信息感知和自主目标探索。相关成果整理成了论文1篇。</p>
<div style="text-align: center;">
    <img src="https://research.xiejialong.top/franka.jpg" width="500"/>
</div>

</li>
<li><p><strong>济南市“新高校20 条”资助科研带头人工作室项目</strong>：机器人超融合云服务平台实用化关键技术研究（2021GXRC079）, 2022.1.1 - 2024.12.31.</p>
<p>主要负责<strong>基于ChatGLM的服务机器人故障诊断问答系统构建</strong>，完成设计服务机器人云平台故障诊断智能助手，构建用于的SFT和RLHF阶段的基于Alapace格式的服务机器人故障-问题数据集，并基于GPT-4进行优化和拓展数据集，使用ChatGLM3-6B作为基础大模型，在LLaMA-Fractory平台上对其进行LoRA微调和DPO对齐，实现了服务机器人故障诊断智能问答系统。</p>
<!-- 运行Demo可以进入网站<a target="_blank" rel="noopener" href="https://cirbot.serveo.net/" style="color: red;">https://cirbot.serveo.net/</a>进行测试。 -->

<div style="text-align: center;">
    <img src="https://research.xiejialong.top/llm.png" width="400"/>
</div>

</li>
<li><p><strong>浙江省重点研发计划项目</strong>：面向养老助残任务的刚-柔-软集成协作机器人设计及智能控制（2019C04018）, 2019.9 - 2022.9</p>
<p>负责<strong>视频动作识别与基于人类反馈的机器人决策生成方案设计</strong>，主要实现视频分析与个性化交互算法设计：</p>
<p>（1）设计基于视频流的动态头势识别算法，基于Tensorflow构建双流3DCNN网络，实现视频流下的实时动态头势识别，并部署在RTX3060服务器与英伟达Jetson TX2开发板；</p>
<p>（2）使用头势识别与表情识别作为显式和隐式的奖励函数模型，使用机器人行为模型作为动作空间，通过人类情感反馈训练DQN模型，实现了机器人主动和被动地做出服务决策。相关工作整理成论文2篇。</p>
  <div style="text-align: center;">
    <img src="https://research.xiejialong.top/pepper.jpg" width="400"/>
</div>

</li>
<li><p><strong>企业合作项目：</strong>无人驾驶汽车模拟系统开发, 2020.12 - 2021.6.  </p>
<p>负责<strong>无人驾驶感知决策方法开发</strong>，主要实现:</p>
<p>（1）基于松灵底盘搭建无人驾驶平台，基于ROS实现Intel NUC工控机与英伟达Jetson Xavier的双机通讯，其中NUC实现数据采集与预处理，Xavier实现视觉模型推理;</p>
<p>（2）基于YOLO实现红绿灯、行人等目标数据采集与微调，并在Xavier和ROS进行部署（3）基于C++完成车道线检测，并利用PID、KCF和卡尔曼滤波算法实现车道线跟踪。</p>
<div style="text-align: center;">
    <img src="https://research.xiejialong.top/car.jpg" width="300"/>
</div></li>
</ul>
<h1 id="实习经历-Intern-Experience"><a href="#实习经历-Intern-Experience" class="headerlink" title="实习经历 Intern Experience"></a>实习经历 Intern Experience</h1><ul>
<li><strong>阿里巴巴菜鸟集团</strong>：自动驾驶大模型算法工程师</li>
</ul>
<p>（1）参与自回归架构VLA模型训练：设计prompt和示例样本，通过Qwen2.5VL-72B清洗业务数据，筛选出1w+文本-图像-轨迹复杂多分布的训练数据，使用LoRA微调Qwen2.5VL-7B模型，轨迹精度提升8%，实现业务上线测试；</p>
<p>（2）针对高速小车实时性要求高和大模型浮点数生成精度不足问题，独立设计VLM+Decoder架构VLA模型：采用InternVL模型作为基座，剪枝其FFN层做快专家，搭建快慢MoE推理架构，提高10% Prefilling速度，构建场景自适应的长短思维链推理，提高20% decode速度。相关创新内容撰写并投稿至 顶会ICLR2026。</p>
<p>（3）尝试外挂驾驶规则RAG方案提升VLA推理能力，并用VeRL库的GRPO算法优化思维链生成，实现多模轨迹预测。</p>
  <div style="text-align: center;">
      <img src="https://research.xiejialong.top/vla.jpg" width="400"/>
  </div>

<h1 id="荣誉与奖励-Honors-and-Award"><a href="#荣誉与奖励-Honors-and-Award" class="headerlink" title="荣誉与奖励 Honors and Award"></a>荣誉与奖励 Honors and Award</h1><ul>
<li>第十七届全国数学建模三等奖 2020年</li>
<li>第十七届浙江省挑战杯三等奖 2021年</li>
<li>杭州电子科技大学优秀毕业生 2022年</li>
<li>第五届全国人工智能创新大赛一等奖 2023年</li>
<li>第六届全国人工智能创新大赛三等奖 2024年</li>
<li>第十九届电子设计竞赛初赛二等奖 2024年</li>
<li>比亚迪学业奖学金 2024年</li>
<li>2023-2024年度优秀研究生</li>
<li>2024-2025年学业一等奖学金</li>
</ul>
<h1 id="进一步了解我-About"><a href="#进一步了解我-About" class="headerlink" title="进一步了解我 About"></a>进一步了解我 About</h1><ul>
<li><i class="fa-brands fa-github"></i> Github: <a target="_blank" rel="noopener" href="https://github.com/xiejialong">https://github.com/xiejialong</a></li>
<li><i class="fa-brands fa-bilibili"></i> Bilibili: <a target="_blank" rel="noopener" href="https://space.bilibili.com/286191903">https://space.bilibili.com/286191903</a></li>
<li><i class="fa-solid fa-blog"></i> CSDN：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Jolen_xie">https://blog.csdn.net/Jolen_xie</a></li>
<li><i class="fa-regular fa-envelope"></i> Eamil: <a href="mailto:jolen_xie@qq.com">jolen_xie@qq.com</a><!-- * <i class="fa-brands fa-tiktok"></i> 抖音号: BeOptimistic.Xie --></li>
</ul>
<head> 
    <script defer src="https://kit.fontawesome.com/6ac35365cd.js"></script> 
</head> 
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css"></article></div></main><div class="nav-wrap"><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2023 - 2026</div><div class="theme-info">Designed by Xie Jialong</div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script><script src="/js/autoslid.js"></script></body></html>